<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description"
    content="Adaptive Horizon Actor-Critic for Policy Learning in Contact-Rich Differentiable Simulation">
  <meta name="keywords" content="Reinforcement Learning, Robot Control, Differentiable Simulation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>AHAC</title>

  <script async src="https://www.googletagmanager.com/gtag/js?id=G-FV4ZJ9PVSV"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-FV4ZJ9PVSV');
  </script>

  <script>
    function updateSingleVideo() {
      var demo = document.getElementById("single-menu-demos").value;
      var task = document.getElementById("single-menu-tasks").value;
      var inst = document.getElementById("single-menu-instances").value;

      console.log("single", demo, task, inst)

      var video = document.getElementById("multi-task-result-video");
      video.src = "media/results/sim_rollouts/" +
        "n" +
        demo +
        "-" +
        task +
        "-" +
        inst +
        ".mp4"
      video.playbackRate = 1.75;
      video.play();
    }

    function updateQpredVideo() {
      var task = document.getElementById("single-menu-qpred").value;

      console.log("qpred", task)

      var video = document.getElementById("q-pred-video");
      video.src = "media/results/qpred/" +
        task +
        ".mp4"
      video.playbackRate = 1.75;
      video.play();
    }

  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body onload="updateSingleVideo(); updateQpredVideo();">

  <!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" target="_blank" href="https://mohitshridhar.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" target="_blank" href="https://cliport.github.io">
            CLIPort
          </a>
          <a class="navbar-item" target="_blank" href="https://askforalfred.com/">
            ALFRED
          </a>
          <a class="navbar-item" target="_blank" href="http://alfworld.github.io/">
            ALFWorld
          </a>
          <a class="navbar-item" target="_blank" href="https://arxiv.org/pdf/1806.03831.pdf">
            INGRESS
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Adaptive Horizon Actor-Critic for Policy Learning in Contact-Rich
              Differentiable Simulation</h1>
            <h3 class="title is-4 conference-authors"><a target="_blank" href="https://www.robot-learning.org/">ICML
                2024 Submission</a></h3>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                Authors hidden while paper is under review.
                <!-- <span class="author-block">
                <a target="_blank" href="https://mohitshridhar.com/">Mohit Shridhar</a><sup>1</sup>,</span> -->
                <!-- <span class="author-block">
                <a target="_blank" href="http://lucasmanuelli.com/">Lucas Manuelli</a><sup>2</sup>,</span>
              <span class="author-block">
                <a target="_blank" href="https://homes.cs.washington.edu/~fox/">Dieter Fox</a><sup>1, 2</sup>
              </span> -->
            </div>

            <!-- <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>University of Washington,</span>
              <span class="author-block"><sup>2</sup>NVIDIA</span>
            </div> -->

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a target="_blank" href="https://openreview.net/forum?id=2FHWFG5ahw"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>

                <!-- Arxiv Link. -->
                <!-- <span class="link-block">
                  <a target="_blank" href="" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file"></i>
                    </span>
                    <span>ArXiv</span>
                  </a>
                </span> -->

                <!-- Video Link. -->
                <!-- <span class="link-block">
                  <a target="_blank" href="https://youtu.be/Pa7tNjtK9w0"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                  </a>
                </span> -->

                <!-- Talk Link.
                <span class="link-block">
                  <a target="_blank" href="https://youtu.be/QcuXwmQgurE"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-chalkboard-teacher"></i>
                    </span>
                    <span>Talk</span>
                  </a>
                </span> -->


                <!-- Colab Link. -->
                <!-- <span class="link-block">
                  <a target="_blank"
                    href="https://colab.research.google.com/drive/1HAqemP4cE81SQ6QO1-N85j5bF4C0qLs0?usp=sharing"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fa fa-book" aria-hidden="true"></i>
                    </span>
                    <span>Colab</span>
                  </a>
                </span> -->

                <!-- Code Link. -->
                <span class="link-block">
                  <a target="_blank" href="https://anonymous.4open.science/r/DiffRL-1D68/README.md"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (Anonymized)</span>
                  </a>
                </span>

              </div>
            </div>


          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-fullhd">
      <div class="hero-body">
        <div class="container">
          <div class="columns is-vcentered  is-centered">
            <div id="wrapper">
              <video id="home1" autoplay muted loop width="100%">
                <source src="media/Hopper_Env_1_compressed.mp4" type="video/mp4">
              </video>
              <video id="home2" autoplay muted loop width="100%">
                <source src="media/AntEnv_1_compressed.mp4" type="video/mp4">
              </video>
            </div>
          </div>

          <br>

          <div class="columns is-vcentered  is-centered">
            <div id="wrapper">
              <video id="home1" autoplay muted loop height="50%">
                <source src="media/AnymalEnv_1_compressed.mp4" type="video/mp4">
              </video>
              <video id="home2" autoplay muted loop height="50%">
                <source src="media/HumanoidEnv_1_compressed.mp4" type="video/mp4">
              </video>
            </div>
          </div>

          <br>

          <div class="columns is-vcentered  is-centered">
            <div id="wrapper">
              <video id="home1" autoplay muted loop height="50%">
                <source src="media/snu_humanoid_SHAC_compressed.mp4" type="video/mp4">
              </video>
              <video id="home2" autoplay muted loop height="50%">
                <source src="media/claw_compressed.mp4" type="video/mp4">
              </video>
            </div>
          </div>
        </div>
        <br>
        <h2 class="subtitle has-text-centered">
          Adaptive Horizon Actor Critic (AHAC) is a First-Order Model-Based Reinforcement Learning algorithm <br>
          that achieves 40% more asymptotic reward than Model-Free approaches across a set of locomotion tasks <br>
          while being 1000x more sample efficient and more scalable to high-dimensional tasks.
        </h2>
      </div>
    </div>
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            Model-Free Reinforcement Learning (MFRL), leveraging the policy gradient theorem, has demonstrated
            considerable success in continuous control tasks. However, these approaches are plagued by high gradient
            variance due to zeroth-order gradient estimation, resulting in suboptimal policies. Conversely, First-Order
            Model-Based Reinforcement Learning~(FO-MBRL) methods employing differentiable simulation provide gradients
            with reduced variance but are susceptible to bias in scenarios involving stiff dynamics, such as physical
            contact. This paper investigates the source of this bias and introduces Adaptive Horizon Actor-Critic
            (AHAC), an FO-MBRL algorithm that reduces gradient bias by adapting the model-based horizon to avoid stiff
            dynamics. Empirical findings reveal that AHAC outperforms MFRL baselines, attaining 40% more reward across a
            set of locomotion tasks and efficiently scaling to high-dimensional control environments with improved
            wall-clock-time efficiency.
          </div>
        </div>
      </div>
      <br>
      <br>
      <!--/ Abstract. -->

    </div>

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-two-thirds">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/Pa7tNjtK9w0?modestbranding=1&autohide=1&showinfo=0&controls=1"
            frameborder="0" allow="encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-widescreen">

      <div class="rows">


        <!-- Animation. -->
        <div class="rows is-centered ">
          <div class="row is-full-width">
            <h2 class="title is-3"><span class="dperact">Adaptive Horizon Actor Critic</span></h2>

            <div class="container">
              <div class="columns is-vcentered  is-centered">
                <img src="media/ahac.png" style="max-width:600px;width:100%" alt="AHAC" />
                </br>
              </div>
              <br>
              In our work we analyze the issues with first-order gradient estimation in differentiable simulation. We
              establish the under finite samples, these types of gradients exhibit empirical bias, particularly under
              stiff dynamics which ocur during contact. To address that we develop a new model-based reinforcement
              learning algorithm, Adaptive Horizon Actor-Critic (AHAC), which adaptively adjusts the horizon of the
              model-based optimization to avoid contact. This allows it to reduce bias and obtain asymptotically more
              optimal policies.

              <br>

              <div class="columns is-vcentered  is-centered">
                <img src="media/ahac_explanation_small.drawio.png" alt="AHAC visual explanation" />
                </br>
              </div>


              <!--/ Re-rendering. -->

              <h2 class="title is-3">Results</h2>

              <div class="container">
                <div class="columns is-vcentered  is-centered">
                  <img src="media/ant_results.png" alt="Ant results" />
                  </br>
                </div>
                <br>
                <h2 class="subtitle has-text-centered">
                  Results from the Ant task show that AHAC outperforms all baselines in terms of asymptotic reward.
                  Since
                  we are mainly comparing against zeroth-order baselines, we normalize all rewards to the maximum
                  achieved
                  by PPO. Even though Ant is widely considered a solved task, we find that AHAC achieves 41% more
                  reward than PPO, even if PPO is left to train for 3B timesteps.
                </h2>
              </div>

              <br>
              <br>

              <div class="container">
                <div class="columns is-vcentered  is-centered">
                  <video autoplay muted loop height="100%">
                    <source src="media/AntEnv_1_vs_PPO_compressed.mp4" type="video/mp4">
                  </video>
                  <br>
                </div>
                <h2 class="subtitle has-text-centered">
                  Qualitatively, AHAC achieves more optimal and natural looking behaviour than our main baseline, PPO.
                </h2>
              </div>

              <br>
              <br>

              <div class="container">
                <div class="columns is-vcentered  is-centered">
                  <img src="media/summary_statistics_combined.png" alt="Summary statistics" />
                  </br>
                </div>
                <br>
                <h2 class="subtitle has-text-centered">
                  <b>Aggregate asymptotic statistics across all tasks.</b> The <b>left</b> figure shows 50\% IQM with
                  95\%
                  CI of asymptotic episode rewards across 10 runs. We observe that AHAC is able to achieve 40\% higher
                  reward than our best MFRL baseline, PPO. The <b>right</b> figure shows score distributions as suggest
                  by \citep{agarwal2021deep} which lets us understand the performance variability of each approach. Our
                  proposed approach, AHAC, outperforms baselines even at the worst case, strengthening the case for
                  first-order methods.
                </h2>
              </div>

              <br>
              <br>

              <div class="container">
                <div class="columns is-vcentered  is-centered">
                  <img src="media/locomotion_sweep.png" alt="Locomotion results" />
                  </br>
                </div>
                <br>
                <h2 class="subtitle has-text-centered">
                  We also run experiments on classic tasks such as Hopper. Real robots such as Anymal. The popular
                  Humanoid task with 21 degrees of freedom and an alternative muscle-actuated version with 152 degrees
                  of
                  freedom which we call SNU Humanoid. We find that AHAC maintains its asymptotic performance across the
                  board. It also exhibits great sample efficiency, requiring 3 order of magnitude less data samples than
                  PPO. Most impressively it also
                  scales significantly better on high dimensional tasks. On the muscle-actuated humanoid, it
                  achieves nearly twice the reward of PPO for the same training time.
                </h2>
              </div>



            </div>
          </div>
  </section>

  <!-- <section class="section" id="BibTeX">
    <div class="container is-max-widescreen content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{shridhar2022peract,
  title     = {Perceiver-Actor: A Multi-Task Transformer for Robotic Manipulation}, 
  author    = {Shridhar, Mohit and Manuelli, Lucas and Fox, Dieter},
  booktitle = {Proceedings of the 6th Conference on Robot Learning (CoRL)},
  year      = {2022},
}</code></pre>
    </div>
  </section> -->


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column">
          <div class="content has-text-centered">
            <p>
              Website template borrowed from <a href="https://github.com/nerfies/nerfies.github.io">NeRFies</a> made by
              the amazing <a href="https://keunhong.com/">Keunhong Park</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>


</body>

</html>